{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Allan R. Jeeboo\n",
    "### Preferred Name: Vyncent S. A. van der Wolvenhuizen\n",
    "### Affiliation: Data Science Student at Triple Ten\n",
    "### Email: vanderwolvenhuizen.vyncent@proton.me\n",
    "### Date started: 2025-03-06\n",
    "### Last updated: 2025-03-09 19:59 EST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Introduction\n",
    "In this project, we'll be assuming the fictional role of being an analyst for Zuber, a new ride-sharing company that's launching in Chicago. Our task is to find patterns in the available information, understand passenger preferences, and the impact of external factors on rides. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Data\n",
    "Let's import the necessary libraries and files for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "\n",
    "try: \n",
    "    company_trips_amount = pd.read_csv('company_name_trips_amount.csv') \n",
    "    dropoff_trips_avg = pd.read_csv('dropoff_trips_avg.csv') \n",
    "    pickup_weather_ride_duration = pd.read_csv('pickup_weather_ride_duration.csv')\n",
    "except: \n",
    "    pd.read_csv('/datasets/project_sql_result_01.csv') \n",
    "    pd.read_csv('/datasets/project_sql_result_04.csv') \n",
    "    pd.read_csv('/datasets/project_sql_result_07.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the first 10 rows of each dataset, along with the number of rows and columns in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "display(company_trips_amount.head(10))\n",
    "print(f'rows, columns: {company_trips_amount.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "display(dropoff_trips_avg.head(10))\n",
    "print(f'rows, columns: {dropoff_trips_avg.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "display(pickup_weather_ride_duration.head(10))\n",
    "print(f'rows, columns: {pickup_weather_ride_duration.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few initial observations:\n",
    "1. There are 64 listed taxi/ride-sharing companies, and 'Flash Cab' seems to have a noticeably higher usage rate compared to its competitors. \n",
    "2. There are 94 listed neighborhoods; the Loop and River North appear to be the most popular drop off location. \n",
    "3. We have data for 1 068 rides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Description \n",
    "An explanation for what each column in each dataset represents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "company_trips_amount description:\n",
    "\n",
    "- **company_name**: Taxi company name.\n",
    "- **trips_amount**: The number of rides for each taxi company on November 15-16, 2017.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropoff_trips_avg information: \n",
    "\n",
    "- **dropoff_location_name**: Chicago neighborhoods where rides ended\n",
    "- **average_trips**: the average number of rides that ended in each neighborhood in November 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickup_weather_ride_duration\n",
    "\n",
    "- **start_ts**: pickup date and time\n",
    "- **weather_conditions**: weather conditions at the moment the ride started\n",
    "- **duration_seconds**: ride duration in seconds\n",
    "\n",
    "Note that the pickup_weather_ride_duration dataset only covers rides from the Loop to O'Hare International Airport and it will only be used for testing whether or not ride duration on Saturdays are affected by weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 Checking company_trips_amount \n",
    "Check for NaNs, duplicates, and ensuring dtypes are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "company_trips_amount.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "company_trips_amount.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "company_trips_amount.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems to be as it should."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Checking dropoff_trips_avg\n",
    "Check for NaNs, duplicates, and ensuring dtypes are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dropoff_trips_avg.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dropoff_trips_avg.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dropoff_trips_avg.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you can't have a fraction of a trip, let's round the values to the nearest integer and then convert the column 'average_trips' to int (note that it's currently a float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dropoff_trips_avg['average_trips'] = dropoff_trips_avg['average_trips'].round().astype(int)\n",
    "dropoff_trips_avg.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Checking pickup_weather_ride_duration\n",
    "Check for NaNs, duplicates, and ensuring dtypes are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pickup_weather_ride_duration.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pickup_weather_ride_duration.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 197 duplicates, so let's drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pickup_weather_ride_duration = pickup_weather_ride_duration.drop_duplicates()\n",
    "pickup_weather_ride_duration.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pickup_weather_ride_duration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pickup_weather_ride_duration.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'duration_seconds' column is a float currently, which is redundant because the values in the column are integers. Let's change the dtype to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pickup_weather_ride_duration['duration_seconds'] = pickup_weather_ride_duration['duration_seconds'].astype(int)\n",
    "pickup_weather_ride_duration.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't much to comment on this section. We have no NaN values and the only minor changes made were converting the columns dropoff_trips_avg['average_trips'] and pickup_weather_ride_duration['duration_seconds'] from floats to ints along with dropping 197 duplicates from the pickup_weather_ride_duration dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Exploratory Data Analysis\n",
    "In this section we'll be performing some EDA. As we have been doing, we'll first start with the company_name_trips_amount dataset and then dropoff_trips_avg. Recall earlier in subsection 1.2 I mentioned that the third dataset, pickup_weather_ride_duration, will only be used for formulating a hypothesis, which will be in section 4.0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Top 10 Neighborhoods by Dropoff\n",
    "First let's identify the top 10 neighborhoods for drop-offs. drop_off_trips_avg should already be sorted off of average_trips in descending order, but for good measure let's ensure that is indeed the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dropoff_trips_avg.average_trips = dropoff_trips_avg.average_trips.sort_values(ascending= False)\n",
    "dropoff_top_ten = dropoff_trips_avg.head(10) \n",
    "dropoff_top_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we can see that trips to 'Loop' and 'River North' have the longest average trips and they are separated from the next two locations - 'Streeterville' and 'West Loop' by a noticeable margin. Continuing further, we see another break between the two aforementioned locations and the following ones. Let's visualize this. To do so, we'll use a simple bar plot. Before we create one though, let's convert 'average_trips' from minutes to seconds so that it's easier to comprehend; e.g., it's simpler to understand a trip that lasted about 178 minutes than one lasting 10,727 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dropoff_top_ten['average_trips'] = (dropoff_top_ten['average_trips'] / 60).astype(int)\n",
    "dropoff_top_ten.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sns.barplot(x='dropoff_location_name', \n",
    "            y='average_trips', \n",
    "            data=dropoff_top_ten)\n",
    "plt.axhline(y=50, color='black', linestyle='--')\n",
    "plt.axhline(y=125, color='black', linestyle='--')\n",
    "plt.xlabel('Drop off Location')\n",
    "plt.ylabel('Average Trip Duration (min)')\n",
    "plt.title('Trip Duration to Dropoff Location')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, we can see that there is a sort of stagger at two locations within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 High Trip Companies\n",
    "Now let's delve into identifying the companies with a significant number of trips. Previously, we noted that there are 64 listed companies. To understand the distribution of trips among these companies, we'll first filter out those with more than 5,000 trips. If necessary, we'll adjust our range to focus on the top ten companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "high_trip_companies = company_trips_amount[company_trips_amount.trips_amount >= 5000]\n",
    "print(high_trip_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 64 companies, only 11 exceed 5000 trips. Our initial data inspection revealed that 'Flash Cab' leads with the highest number of trips, and this filter confirms its substantial lead over other companies.\n",
    "\n",
    "To gain further insights, let's view these values as percentages. We'll sum the 'trips_amount' column, divide each company's trips by this total, and then focus on the top ten companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "trips_sum = company_trips_amount['trips_amount'].sum()\n",
    "normalized_trips_df = company_trips_amount[['company_name']].copy()\n",
    "normalized_trips_df['normalized_trips'] = (company_trips_amount['trips_amount'] / trips_sum)\n",
    "normalized_trips_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Flash Cab' holds a significant 14.2% share of the market, leading 'Taxi Affiliation Services' by approximately 5.9%. Compared to the 10th most utilized company, 'Flash Cab' has a notable 9.9% advantage. This indicates a strong dominance in the Chicago taxi/ride-share market. Given that there are 64 companies in the dataset, it suggests a pronounced right skew in the distribution of trips. Rather than an even distribution of rides among companies, a few companies hold a large share of the market. Let's visualize this via an interactive scatter plot. To elaborate, instead of seeing an even distribution of rides between companies, we see a few companies holding a large share of the market. Let's visualize this via an interactive scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "fig = px.scatter(company_trips_amount, \n",
    "                 x=company_trips_amount.index, \n",
    "                 y='trips_amount', \n",
    "                 hover_name='company_name', \n",
    "                 trendline= 'lowess', \n",
    "                 trendline_options=dict(frac=0.225))\n",
    "fig.update_layout(title={'text': 'Number of Trips Per Company', \n",
    "                         'x': 0.5},\n",
    "                  xaxis_title='Company Name', \n",
    "                  xaxis_showticklabels=False, \n",
    "                  yaxis_title='Amount of Trips')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are there four distinct linear segments in the data? Specifically, 'Flash Cab' is an outlier, followed by a sharp decline from index[1:15]. From index[14:26], the slope is less steep, then from index[25:36], the slope is almost flat, with the remaining data showing nearly zero slope. I've added a lowess trendline to aid in seeing the trend.\n",
    "\n",
    "Let's look at the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sns.displot(data=company_trips_amount, legend=False)\n",
    "plt.xlabel('Trips Amount')\n",
    "plt.ylabel('Company Count')\n",
    "plt.title('Number of Companies That Made x Amount of Trips', loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "low_trip_companies = company_trips_amount[company_trips_amount.trips_amount < 1000]\n",
    "print(low_trip_companies.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph along with the previous one shows that there certainly is not an even distribution of trips between companies. A significant amount of these companies recieve few rides. In addition to that, the code cell above shows that out of the 64 companies, 39 have less than 1000 trips, which is ~61% of the companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 EDA Conclusion \n",
    "To summarize our gatherings:  \n",
    "- Rides to the Loop and River North have the longest duration; the former takes approximately 178 minutes, while the latter takes roughly 158 minutes.\n",
    "- 'Flash Cab' dominates the taxi/ride-share market with 19,558 trips, which is 14.2% of all trips in the dataset. \n",
    "- Of the 64 companies in the dataset, only 11 have  >5,000 trips, while 39 have <1,000 trips. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Hypothesis\n",
    "Does the average duration of rides from the Loop to O'Hare International Airport change on rainy Saturdays?\n",
    "\n",
    "**Null Hypothesis (H0):**  \n",
    "Rainy Saturdays do not affect trip duration from the Loop to O'Hare International Airport.\n",
    "\n",
    "**Alternative Hypothesis (H1):**  \n",
    "Weather conditions and the day of the week do affect trip duration from the Loop to O'Hare International Airport.\n",
    "\n",
    "**Formulation of Hypotheses:**  \n",
    "The null hypothesis posits that there is no significant difference between a subset of data and the overall dataset. Conversely, the alternative hypothesis suggests the opposite. In this context, we are considering two variables: weather and day of the week. Our null hypothesis asserts that trip duration remains unaffected by these variables, while our alternative hypothesis contends that both weather conditions and the day of the week significantly influence trip duration.\n",
    "\n",
    "**Days in November 2017 that were Saturdays:**  \n",
    "The 4th, 11th, 18th, and 25th of November 2017 were Saturdays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Hypothesis Approach\n",
    "We need pickup_weather_ride_duration['weather_conditions'] and dropoff_trips_avg['dropoff_location_name'] to test this hypothesis, so we'll create an empty column in both dataframes named 'temporary_column' in order to have something in common for the dataframes to merge on; after the merge, we'll drop the redundant column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column to merge the dataframes\n",
    "pickup_weather_ride_duration['temporary_column'] = None\n",
    "dropoff_trips_avg['temporary_column'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Merging the dataframes\n",
    "df_joined = pickup_weather_ride_duration.join(dropoff_trips_avg.set_index('temporary_column'), \n",
    "                                              on='temporary_column')\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Dropping the temporary column\n",
    "df_joined = df_joined.drop(columns=['temporary_column'])\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert the start_ts column to datetime using the pandas method to_datetime so that we can filter the dataframe for Saturdays. Then we'll split the dataframe into two based on whether the weather is good or bad, ensure that only information for Saturdays is present, and that the drop off location is O'Hare International Airport. Afterwards, we'll print the first five rows of both dataframes along with the shape for a quick overview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.start_ts = pd.to_datetime(df_joined.start_ts)\n",
    "\n",
    "df_good_saturdays = df_joined[(df_joined['weather_conditions'] == 'Good') & \n",
    "                              (df_joined['start_ts'].dt.dayofweek == 5) & \n",
    "                              (df_joined['dropoff_location_name'] == \"O'Hare\")].drop(columns=['average_trips'])\n",
    "\n",
    "df_bad_saturdays = df_joined[(df_joined['weather_conditions'] == 'Bad') & \n",
    "                             (df_joined['start_ts'].dt.dayofweek == 5) & \n",
    "                             (df_joined['dropoff_location_name'] == \"O'Hare\")].drop(columns=['average_trips'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print('Good Saturdays:')\n",
    "display(df_good_saturdays.head(), df_good_saturdays.shape)\n",
    "print('Bad Saturdays:')\n",
    "display(df_bad_saturdays.head(), df_bad_saturdays.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's calculate the average trip duration depending on weather condition. To do so, we'll take the sum of the duration_seconds column in both tables, then divide by the number of rows in the respective dataset and convert the result to an integer. I've chosen to do this because the column represents seconds; having a float value is far too specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "good_duration_sum = df_good_saturdays['duration_seconds'].sum()\n",
    "bad_duration_sum = df_bad_saturdays['duration_seconds'].sum()\n",
    "\n",
    "good_trip_avg = int(good_duration_sum / df_good_saturdays['duration_seconds'].count())\n",
    "bad_trip_avg = int(bad_duration_sum / df_bad_saturdays['duration_seconds'].count())\n",
    "\n",
    "display(f'Trip average during good weather: {good_trip_avg} seconds', \n",
    "        f'Trip average during bad weather: {bad_trip_avg} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "good_trip_avg_min = round(good_trip_avg / 60)\n",
    "bad_trip_avg_min = round(bad_trip_avg / 60)\n",
    "\n",
    "display(f'Trip average during good weather: {good_trip_avg_min} minutes', \n",
    "        f'Trip average during bad weather: {bad_trip_avg_min} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results above indicate that there is a difference in ride duration from the Loop to O'Hare International Airport depending on weather condition. When the weather is good, a trip on average lasts 34 minutes, whereas during bad weather, the duration is approximately 40 minutes. Upon testing the p-value, a conclusion will be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 P-value test\n",
    "Let's now test the p-value. Because the information were working with doesn't need to be so stringent as to use a value of say, 0.01, we'll use the commonplace threshold of 0.05, represented by the variable 'alpha'. Remember we are testing whether or no ride duration is affected by weather, so we'll use the 'duration_seconds' column from both dataframes representing good and bad weather. \n",
    "\n",
    "If the p-value is >0.05, then we accept the null hypothesis. As a reminder, our null hypothesis is as follows:  \n",
    "- Rainy Saturdays do not affect trip duration from the Loop to O'Hare International Airport.\n",
    "\n",
    "If the p-value is <0.05 then we reject the null hypothesis. As a reminder, our alternative hypothesis is as follows:  \n",
    "- Weather conditions and the day of the week do affect trip duration from the Loop to O'Hare International Airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind (df_good_saturdays['duration_seconds'], \n",
    "                                   df_bad_saturdays['duration_seconds'], \n",
    "                                   equal_var= True)\n",
    "\n",
    "print(f'p-value: {p_value}')\n",
    "\n",
    "if p_value > 0.05: \n",
    "    print('We accept the null hypothesis')\n",
    "else: \n",
    "    print('We reject the null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our p-value is far below our the p-value hypothesis, therefore we reject the null hypothesis. Our results suggest that there is indeed a difference in ride duration based on weather conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Conclusion\n",
    "\n",
    "In this section, we will recap the key findings of this project and provide a comprehensive summary of our results.\n",
    "\n",
    "**Top Ten Neighborhoods for Drop-offs**  \n",
    "The top ten neighborhoods for drop-offs, listed in descending order, are:\n",
    "- The Loop\n",
    "- River North\n",
    "- Streeterville\n",
    "- West Loop\n",
    "- O'Hare International Airport\n",
    "- Lake View\n",
    "- Grant Park\n",
    "- Museum Campus\n",
    "- Gold Coast\n",
    "- Sheffield & DePaul\n",
    "\n",
    "**Observations on Top Ten Neighborhoods**\n",
    "- Trips to the Loop and River North have the longest durations, averaging 178 minutes and 158 minutes, respectively.\n",
    "- There are two significant drops in trip duration: the first between River North and Streeterville, where the latter averages 111 minutes, a 42% decrease from River North's 158 minutes. The second drop occurs between West Loop and O'Hare, with the former averaging 86 minutes and the latter 42 minutes, less than half the time of the former.\n",
    "\n",
    "**Top Ten Taxi/Ride-Sharing Companies**  \n",
    "The top ten companies, in descending order, are:\n",
    "- Flash Cab\n",
    "- Taxi Affiliation Services\n",
    "- Medallion Leasin\n",
    "- Yellow Cab\n",
    "- Taxi Affiliation Services Yellow\n",
    "- Chicago Carriage Cab Corp\n",
    "- City Service\n",
    "- Sun Taxi\n",
    "- Star North Management LLC\n",
    "- Blue Ribbon Taxi Association Inc.\n",
    "\n",
    "**Observations on High Trip Companies**\n",
    "- Flash Cab dominates the market with 19,558 trips, accounting for 14.2% of all trips. The second most used service, Taxi Affiliation Services, has 11,422 trips, representing 8.3% of all trips.\n",
    "- Out of the 64 companies listed, only 11 have provided over 5,000 rides, while 39 have fewer than 1,000 rides, which is approximately 61% of the companies. This indicates a concentration of business among a few companies rather than an even distribution.\n",
    "\n",
    "**Impact of Weather on Trip Duration**\n",
    "- Trips from the Loop to O'Hare average 34 minutes during good weather and approximately 40 minutes during bad weather. Using a significance threshold of 0.05, we obtained a p-value of 7.397770692813658e-08, leading us to reject the null hypothesis. This suggests that weather conditions do indeed affect trip duration.\n",
    "\n",
    "**Possible Reasons for Longer Trip Durations During Bad Weather**\n",
    "- Drivers may exercise more caution.\n",
    "- The likelihood of accidents increases, potentially causing delays.\n",
    "- Flooding or other hazardous conditions may necessitate detours, slowing travel time.\n",
    "\n",
    "In conclusion, our analysis reveals significant insights into trip durations and the distribution of trips among neighborhoods and companies. Additionally, we have established that weather conditions have a measurable impact on trip durations from the Loop to O'Hare International Airport."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
